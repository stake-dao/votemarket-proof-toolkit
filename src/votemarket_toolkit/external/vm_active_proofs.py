import argparse
import asyncio
import json
import os
from datetime import datetime
from typing import Any, Dict, List, Tuple

from dotenv import load_dotenv
from rich.console import Console
from rich.panel import Panel

from votemarket_toolkit.campaigns.services.campaign_service import (
    CampaignService,
)
from votemarket_toolkit.campaigns.services.data_service import (
    VoteMarketDataService,
)
from votemarket_toolkit.proofs import VoteMarketProofs
from votemarket_toolkit.shared.types import AllProtocolsData, ProtocolData
from votemarket_toolkit.utils import get_rounded_epoch
from votemarket_toolkit.votes.services.votes_service import votes_service

load_dotenv()

TEMP_DIR = "temp"
console = Console()

# Initialize services
campaign_service = CampaignService()
vm_proofs = VoteMarketProofs(1)
vm_votes = VoteMarketDataService(1)


def is_campaign_active(campaign: dict) -> bool:
    """Check if a campaign is active and should be processed."""
    current_timestamp = int(datetime.now().timestamp())
    return (
        not campaign["is_closed"]
        and campaign["details"]["end_timestamp"] > current_timestamp
        and campaign["period_left"] > 0
    )


async def process_gauge(
    protocol: str,
    gauge_address: str,
    current_epoch: int,
    block_number: int,
    user_proofs_cache: Dict[str, Any],
) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    Process a gauge by generating its proof and gathering vote details.

    Returns:
      - gauge_proof_data: containing proofs (e.g. point_data_proof and storage proofs for each user).
      - gauge_vote_data: containing only the raw vote details for each eligible user.
    """
    console.print(
        f"Querying votes for gauge: [magenta]{gauge_address}[/magenta]"
    )
    gauge_votes = await votes_service.get_gauge_votes(
        protocol, gauge_address, block_number
    )
    console.print(
        f"Found [yellow]{len(gauge_votes.votes)}[/yellow] votes for gauge: [magenta]{gauge_address}[/magenta]"
    )

    console.print("Generating point data proof")
    gauge_proofs = vm_proofs.get_gauge_proof(
        protocol=protocol,
        gauge_address=gauge_address,
        current_epoch=current_epoch,
        block_number=block_number,
    )
    gauge_proof_data = {
        "point_data_proof": "0x" + gauge_proofs["point_data_proof"].hex(),
        "users": {},
    }
    gauge_vote_data = {"users": {}}

    console.print(
        f"Querying eligible users for gauge: [magenta]{gauge_address}[/magenta]"
    )
    eligible_users = await vm_votes.get_eligible_users(
        protocol, gauge_address, current_epoch, block_number
    )
    console.print(
        f"Found [yellow]{len(eligible_users)}[/yellow] eligible users for gauge: [magenta]{gauge_address}[/magenta]"
    )

    for user in eligible_users:
        user_address = user["user"].lower()
        cache_key = f"{gauge_address}:{user_address}"
        if cache_key not in user_proofs_cache:
            console.print(
                f"Generating proof for user: [cyan]{user_address}[/cyan]"
            )
            user_proofs = vm_proofs.get_user_proof(
                protocol=protocol,
                gauge_address=gauge_address,
                user=user_address,
                block_number=block_number,
            )
            user_proofs_cache[cache_key] = {
                "storage_proof": "0x" + user_proofs["storage_proof"].hex(),
                "last_vote": user["last_vote"],
                "slope": user["slope"],
                "power": user["power"],
                "end": user["end"],
            }
        proof_info = user_proofs_cache[cache_key]
        # In gauge proofs, only include the storage proof.
        gauge_proof_data["users"][user_address] = {
            "storage_proof": proof_info["storage_proof"]
        }
        # In vote data, include only the raw vote details.
        gauge_vote_data["users"][user_address] = {
            "last_vote": proof_info["last_vote"],
            "slope": proof_info["slope"],
            "power": proof_info["power"],
            "end": proof_info["end"],
        }
    return gauge_proof_data, gauge_vote_data


def process_listed_users(
    protocol: str,
    gauge_address: str,
    block_number: int,
    listed_users: List[str],
) -> Dict[str, Any]:
    """
    Process the listed users for a campaign by generating a storage proof.
    (Listed users do not include raw vote details.)
    """
    listed_users_data = {}
    for listed_user in listed_users:
        console.print(
            f"Generating proof for listed user: [cyan]{listed_user}[/cyan]"
        )
        user_proofs = vm_proofs.get_user_proof(
            protocol=protocol,
            gauge_address=gauge_address,
            user=listed_user,
            block_number=block_number,
        )
        listed_users_data[listed_user.lower()] = {
            "storage_proof": "0x" + user_proofs["storage_proof"].hex()
        }
    return listed_users_data


async def process_protocol(
    protocol: str, protocol_data: ProtocolData, current_epoch: int
) -> Dict[str, Any]:
    """
    Process each chain for the protocol and generate parallel structures:
      - "platforms": for proofs (stored in index/gauge files)
      - "votes": for raw vote details only (to be stored in a separate file)
    """
    platforms_by_chain = protocol_data[
        "platforms"
    ]  # chain_id -> list of platform dicts
    current_epoch = get_rounded_epoch(current_epoch)
    output_data: Dict[str, Any] = {"chains": {}, "platforms": {}}
    output_data["votes"] = {}  # Separate vote details

    # Global caches for gauge proofs and vote details.
    gauge_proofs_cache: Dict[str, Dict[str, Any]] = {}
    gauge_votes_cache: Dict[str, Dict[str, Any]] = {}
    user_proofs_cache: Dict[str, Dict[str, Any]] = {}

    for chain_id, platforms_list in platforms_by_chain.items():
        if not platforms_list:
            continue

        # Use the first platformâ€™s data as representative.
        rep_platform = platforms_list[0]
        block_number = rep_platform["latest_setted_block"]

        output_data["chains"][chain_id] = {
            "chain_id": chain_id,
            "platform_address": rep_platform["address"],
            "block_data": rep_platform["block_data"],
            "gauge_controller_proof": None,
        }
        output_data["platforms"][chain_id] = {}
        output_data["votes"].setdefault(chain_id, {})

        with console.status(
            f"[cyan]Generating gauge controller proof for chain {chain_id}...[/cyan]"
        ):
            gauge_controller = vm_proofs.get_gauge_proof(
                protocol=protocol,
                gauge_address="0x0000000000000000000000000000000000000000",
                current_epoch=current_epoch,
                block_number=block_number,
            )
            output_data["chains"][chain_id]["gauge_controller_proof"] = (
                "0x" + gauge_controller["gauge_controller_proof"].hex()
            )

        # Process each platform for this chain.
        for platform_data in platforms_list:
            platform_address = platform_data["address"]
            block_number = platform_data["latest_setted_block"]

            if platform_address not in output_data["platforms"][chain_id]:
                output_data["platforms"][chain_id][platform_address] = {
                    "block_data": platform_data["block_data"],
                    "gauges": {},
                }
            if platform_address not in output_data["votes"][chain_id]:
                output_data["votes"][chain_id][platform_address] = {
                    "gauges": {},
                }

            # Query active campaigns (used to process gauges) but do not store globally.
            with console.status(
                f"[magenta]Querying active campaigns for platform {platform_address} on chain {chain_id}...[/magenta]"
            ):
                campaign_svc = CampaignService()
                all_campaigns = await campaign_svc.query_active_campaigns(
                    chain_id, platform_address
                )
                active_campaigns = [
                    c for c in all_campaigns if is_campaign_active(c)
                ]
                if len(active_campaigns) < len(all_campaigns):
                    console.print(
                        f"[yellow]Filtered out {len(all_campaigns) - len(active_campaigns)} inactive campaigns for platform {platform_address}[/yellow]"
                    )

            # Process each campaign for the platform.
            for campaign in active_campaigns:
                gauge_address = campaign["gauge"].lower()
                if not vm_proofs.is_valid_gauge(protocol, gauge_address):
                    continue

                composite_campaign_id = (
                    f"{platform_address.lower()}-{campaign['id']}"
                )
                if gauge_address not in gauge_proofs_cache:
                    console.print(
                        Panel(
                            f"Processing gauge: [magenta]{gauge_address}[/magenta] on {platform_address}"
                        )
                    )
                    with console.status(
                        "[green]Processing gauge data...[/green]"
                    ):
                        (
                            gauge_proof_data,
                            gauge_vote_data,
                        ) = await process_gauge(
                            protocol,
                            gauge_address,
                            current_epoch,
                            block_number,
                            user_proofs_cache,
                        )
                    # For proofs, store campaign IDs and listed users per gauge.
                    gauge_proof_data["active_campaigns_ids"] = [
                        composite_campaign_id
                    ]
                    gauge_proof_data["listed_users"] = {
                        composite_campaign_id: process_listed_users(
                            protocol,
                            gauge_address,
                            block_number,
                            campaign["listed_users"],
                        )
                    }
                    gauge_proofs_cache[gauge_address] = gauge_proof_data
                    # For votes, keep only the raw vote details.
                    gauge_votes_cache[gauge_address] = {
                        "users": gauge_vote_data["users"]
                    }
                else:
                    gauge_proof_data = gauge_proofs_cache[gauge_address]
                    # Merge vote data if needed.
                    new_vote_data = (
                        await process_gauge(
                            protocol,
                            gauge_address,
                            current_epoch,
                            block_number,
                            user_proofs_cache,
                        )
                    )[1]["users"]
                    gauge_votes_cache[gauge_address]["users"].update(
                        new_vote_data
                    )
                    # Append the campaign id if not already present.
                    if composite_campaign_id not in gauge_proof_data.get(
                        "active_campaigns_ids", []
                    ):
                        gauge_proof_data.setdefault(
                            "active_campaigns_ids", []
                        ).append(composite_campaign_id)
                        gauge_proof_data.setdefault("listed_users", {})[
                            composite_campaign_id
                        ] = process_listed_users(
                            protocol,
                            gauge_address,
                            block_number,
                            campaign["listed_users"],
                        )
                # Save gauge proof data for this platform.
                output_data["platforms"][chain_id][platform_address]["gauges"][
                    gauge_address
                ] = gauge_proof_data
                # Save gauge vote data (raw vote details) for this platform.
                output_data["votes"][chain_id][platform_address].setdefault(
                    "gauges", {}
                )[gauge_address] = gauge_votes_cache[gauge_address]

        console.print(
            f"Finished processing chain {chain_id} for protocol: [blue]{protocol}[/blue]"
        )
    return output_data


def write_protocol_data(
    protocol: str, current_epoch: int, processed_data: Dict[str, Any]
):
    """
    Write processed protocol data to files using the new folder structure.

    This writes:
      - The protocol header and index (proofs only) in header.json and index.json.
      - Individual gauge files under each platform/chain folder.
      - A separate votes.json file containing only vote data (raw vote details), along with epoch and block_data.
    """
    protocol_dir = os.path.join(TEMP_DIR, protocol.lower())
    os.makedirs(protocol_dir, exist_ok=True)

    # Build platforms index for proofs.
    platforms_by_address: Dict[str, Dict[str, Any]] = {}
    for chain_id, chain_platforms in processed_data["platforms"].items():
        for platform_addr, platform_data in chain_platforms.items():
            platforms_by_address.setdefault(platform_addr, {})[chain_id] = {
                "chain_id": chain_id,
                "platform_address": platform_addr,
                "block_data": processed_data["chains"]
                .get(chain_id, {})
                .get("block_data", {}),
                "gauges": platform_data.get("gauges", {}),
            }

    rep_platform_addr = next(iter(platforms_by_address))
    rep_chain_id = next(iter(platforms_by_address[rep_platform_addr]))
    rep_chain_header = processed_data["chains"].get(rep_chain_id, {})

    # Write protocol-level header.
    header_data = {
        "epoch": current_epoch,
        "block_data": rep_chain_header.get("block_data", {}),
        "gauge_controller_proof": rep_chain_header.get(
            "gauge_controller_proof", ""
        ),
    }
    with open(os.path.join(protocol_dir, "header.json"), "w") as f:
        json.dump(header_data, f)

    # Write main index file (proofs only).
    index_data = {
        "epoch": current_epoch,
        "block_data": rep_chain_header.get("block_data", {}),
        "gauge_controller_proof": rep_chain_header.get(
            "gauge_controller_proof", ""
        ),
        "platforms": platforms_by_address,
    }
    with open(os.path.join(protocol_dir, "index.json"), "w") as f:
        json.dump(index_data, f)

    # Write individual gauge files for each platform/chain (proofs only).
    for platform_addr, chains in platforms_by_address.items():
        platform_folder = os.path.join(protocol_dir, platform_addr.lower())
        os.makedirs(platform_folder, exist_ok=True)
        for chain_id, chain_info in chains.items():
            chain_folder = os.path.join(platform_folder, chain_id)
            os.makedirs(chain_folder, exist_ok=True)
            with open(os.path.join(chain_folder, "index.json"), "w") as f:
                json.dump(chain_info, f)
            for gauge_address, gauge_data in chain_info["gauges"].items():
                gauge_file = os.path.join(
                    chain_folder, f"{gauge_address.lower()}.json"
                )
                with open(gauge_file, "w") as f:
                    json.dump(gauge_data, f)
            console.print(
                f"Saved gauge files for platform [cyan]{platform_addr}[/cyan] on chain [blue]{chain_id}[/blue] in {chain_folder}"
            )

    # Build and write the votes file (only gauge vote details plus epoch and block_data).
    votes_platforms: Dict[str, Any] = {}
    votes_data = processed_data.get("votes", {})
    for chain_id, chain_platforms in votes_data.items():
        for platform_addr, platform_data in chain_platforms.items():
            votes_platforms.setdefault(platform_addr, {})[chain_id] = {
                "gauges": platform_data.get("gauges", {})
            }
    votes_index_data = {
        "epoch": current_epoch,
        "block_data": rep_chain_header.get("block_data", {}),
        "platforms": votes_platforms,
    }
    with open(os.path.join(protocol_dir, "votes.json"), "w") as f:
        json.dump(votes_index_data, f)


async def main(all_protocols_data: AllProtocolsData, current_epoch: int):
    console.print(
        f"Starting active proofs generation for epoch: [yellow]{current_epoch}[/yellow]"
    )
    for protocol, protocol_data in all_protocols_data["protocols"].items():
        if not protocol_data["platforms"]:
            console.print(
                f"Skipping protocol: [blue]{protocol}[/blue] as no platforms found"
            )
            continue
        console.print(f"Processing protocol: [blue]{protocol}[/blue]")
        processed_data = await process_protocol(
            protocol, protocol_data, current_epoch
        )
        write_protocol_data(protocol.lower(), current_epoch, processed_data)
    console.print(
        "[bold green]Finished generating active proofs for all protocols[/bold green]"
    )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Generate active proofs for protocols"
    )
    parser.add_argument(
        "all_platforms_file",
        type=str,
        help="Path to the JSON file containing all platforms data",
    )
    parser.add_argument(
        "current_epoch", type=int, help="Current epoch timestamp"
    )
    args = parser.parse_args()

    with open(args.all_platforms_file, "r") as f:
        all_protocols_data = json.load(f)

    asyncio.run(main(all_protocols_data, args.current_epoch))
    console.print(
        "[bold green]Active proofs generation script completed[/bold green]"
    )
